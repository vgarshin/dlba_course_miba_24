{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0041bf28-aeb3-494f-bcbe-7f06e53720f8",
   "metadata": {},
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237c64a-03ad-4d53-bd5a-65eb21451686",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TOPIC 4: Object detection problem. Mask R-CNN demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0203cd94-d0fe-477b-a38b-b1df886cc3e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7984e0-2f00-4aa5-8339-040ad86a1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6afd3-7d3e-4f86-a1fe-678acd09d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "\n",
    "# check if GPU available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfad365-9eed-415b-a7db-06908795cc81",
   "metadata": {},
   "source": [
    "### 2. Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41514806-07b8-4d35-9fb0-76de9c03e7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dc312-11ce-4334-8b83-25d9d1de59a3",
   "metadata": {},
   "source": [
    "Where is my model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4b7f5-e3df-4f53-8ed6-a43f60354342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -la ~/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf49a5-0947-4565-941e-2ca89eca291b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -la ~/.cache/torch/hub/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e6986-1cae-485e-a638-f046a0091eb0",
   "metadata": {},
   "source": [
    "__NOTE:__ keep in mind disk space required for models downloads!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd39d8-a57f-4df5-809b-bb5eb26b305e",
   "metadata": {},
   "source": [
    "### 3. Model inference utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ac646-57ff-40f6-8c9d-fe037bde273e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209040c0-85fc-49b5-bb22-5ea07b5432a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "print(\n",
    "    'total COCO classes:',\n",
    "    len(COCO_INSTANCE_CATEGORY_NAMES)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d312e-ff31-42a2-9612-f75ce725f0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prediction(model, img_path, threshold):\n",
    "    \"\"\"\n",
    "    Extracts masks, classes, bounding boxes\n",
    "    from model\n",
    "\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    transform = v2.Compose([v2.ToTensor()])\n",
    "    img = transform(img)\n",
    "    pred = model([img])\n",
    "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1]\n",
    "    masks = (pred[0]['masks'] > .5).squeeze().detach().cpu().numpy()\n",
    "    pred_class = [\n",
    "        COCO_INSTANCE_CATEGORY_NAMES[i] \n",
    "        for i in list(pred[0]['labels'].numpy())\n",
    "    ]\n",
    "    pred_boxes = [\n",
    "        [(i[0], i[1]), (i[2], i[3])] \n",
    "        for i in list(pred[0]['boxes'].detach().numpy())\n",
    "    ]\n",
    "    masks = masks[:pred_t+1]\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    return masks, pred_boxes, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c780c-06cd-4b79-84c5-bbc018718a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_colour_masks(image):\n",
    "    \"\"\"\n",
    "    Produces the colored masks with random color\n",
    "\n",
    "    \"\"\"\n",
    "    colours = [\n",
    "      [0, 255, 0],\n",
    "      [0, 0, 255],\n",
    "      [255, 0, 0],\n",
    "      [0, 255, 255],\n",
    "      [255, 255, 0],\n",
    "      [255, 0, 255],\n",
    "      [80, 70, 180],\n",
    "      [250, 80, 190],\n",
    "      [245, 145, 50],\n",
    "      [70, 150, 250],\n",
    "      [50, 190, 190]\n",
    "    ]\n",
    "    r = np.zeros_like(image).astype(np.uint8)\n",
    "    g = np.zeros_like(image).astype(np.uint8)\n",
    "    b = np.zeros_like(image).astype(np.uint8)\n",
    "    r[image == 1], g[image == 1], b[image == 1] = colours[random.randrange(0, 10)]\n",
    "    coloured_mask = np.stack([r, g, b], axis=2)\n",
    "    return coloured_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d253c43-a4a0-4412-ba66-113fda646f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def instance_segmentation_api(model, img_path,\n",
    "                              threshold=.75, rect_th=2,\n",
    "                              text_size=1, text_th=2):\n",
    "    \"\"\"\n",
    "    Plots the final result for image\n",
    "\n",
    "    \"\"\"\n",
    "    masks, boxes, pred_cls = get_prediction(model, img_path, threshold)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    for i in range(len(masks)):\n",
    "        rgb_mask = random_colour_masks(masks[i])\n",
    "        img = cv2.addWeighted(img, 1, rgb_mask, 0.5, 0)\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            [int(x) for x in boxes[i][0]],\n",
    "            [int(x) for x in boxes[i][1]],\n",
    "            color=(0, 255, 0),\n",
    "            thickness=rect_th\n",
    "        )\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            pred_cls[i],\n",
    "            [int(x) for x in boxes[i][0]],\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            text_size,\n",
    "            (0, 255, 0),\n",
    "            thickness=text_th\n",
    "        )\n",
    "    plt.figure(figsize=(20, 30))\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba23db-acf6-4899-bf5e-d11ef10c8c07",
   "metadata": {},
   "source": [
    "### 4. Model inference examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa1089-0fbc-4c69-b6e1-62d95ce5cafd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's use this excellent [comedy film](https://en.wikipedia.org/wiki/Attack_of_the_Killer_Tomatoes) for our tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247ae5d-f2a6-4d02-b9bf-cf33c88d5820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/jovyan/__DATA/DLBA_F24/topic_04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202567c3-e49c-4dcb-9d3a-d63206a01fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = f'{DATA_PATH}/tomato1.jpg'\n",
    "instance_segmentation_api(model, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5ef97-04e3-4786-ace8-966703611ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks, boxes, pred_cls = get_prediction(model, img_path, threshold=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58300ae-70a3-41d3-999f-556a42d0db09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_cls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667de0b-1037-483e-b3dd-d181e22cba5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db2623-e6d7-4f13-9d4b-472fb7543109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ce898-0dca-4f90-ab70-189f7318e093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(masks[num])\n",
    "plt.title(pred_cls[num])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6f5fc-1842-4fe0-aba2-e886c9552010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = f'{DATA_PATH}/tomato2.jpg'\n",
    "instance_segmentation_api(model, img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875b32a-9ad1-4c8c-80eb-cda886e62abf",
   "metadata": {},
   "source": [
    "More samples for [another comedy](https://en.wikipedia.org/wiki/Ace_Ventura:_Pet_Detective)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29afbd8-d9de-433a-9df0-5f7d4fcf1f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = f'{DATA_PATH}/ace.jpg'\n",
    "instance_segmentation_api(model, img_path, text_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3318db4-0fd6-4863-abdf-2329cad98fae",
   "metadata": {},
   "source": [
    "...and finally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd66549-993a-45b8-8434-47b3210b1857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = f'{DATA_PATH}/foods.jpg'\n",
    "instance_segmentation_api(model, img_path, threshold=.9, text_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc96cfc-2291-4cd5-8aff-4c60dcdb7e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
