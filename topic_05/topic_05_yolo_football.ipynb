{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313a1cf8-d7b5-43c8-827a-536f43451e94",
   "metadata": {},
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99298500-49a1-4f19-99f4-376c16587ef8",
   "metadata": {},
   "source": [
    "## TOPIC 5: Object detection problem. Play football with YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861dc3f-7b29-429c-bcdf-c23c89631500",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b609e-7fdd-442a-9df2-8cf1d1ab6b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install opencv-python\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1904a-0b91-44f3-8e58-22f87b7affbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db892c-f301-4b0c-b70e-7536f6ad3dd9",
   "metadata": {},
   "source": [
    "### 2. Video to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ae667-0484-41f1-b0f7-a1defc99a1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -la /home/jovyan/__DATA/DLBA_F24/topic_02/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476eeb2-5dbb-4b8f-807c-a385262094bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_path = '/home/jovyan/__DATA/DLBA_F24/topic_02/videoplayback.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be62899e-8205-4528-b4a3-b9b21ea88aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# open the video from the file\n",
    "\n",
    "cap = cv2.VideoCapture(vid_path)\n",
    "frames_cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print('video has {} frames and rate {} fps (frames-per-second)'.format(\n",
    "    frames_cnt,\n",
    "    fps\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437e145-5bb9-473b-be03-ce99fe3c3c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_frames(vid_path, start_time, num_frames, save_dir):\n",
    "    \"\"\"\n",
    "    Function takes the path to video\n",
    "    and saves few frames to the disk.\n",
    "\n",
    "    :vid_path: path to video file\n",
    "    :start_time: where to start capturing frames\n",
    "    :num_frames: ho many frames to save\n",
    "    :save_dir: path to save to\n",
    "\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    frames_cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    start_pos = int(start_time * fps)\n",
    "    end_pos = int(start_pos + num_frames)\n",
    "    if end_pos <= frames_cnt:\n",
    "        for frame_num in range(start_pos, end_pos):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            res, frame = cap.read()\n",
    "            if res:\n",
    "                file_name = '{}/frame_{}.png'.format(save_dir, frame_num)\n",
    "                cv2.imwrite(file_name, frame)\n",
    "    else:\n",
    "        print('out of video lenght')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9158b7c-422d-4ec3-8757-22530d9f0a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORK_DIR = 'yolofootball'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f5577-cf6b-43b8-811b-e51bf704ee36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p $WORK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee88be0-439a-4f42-8cb6-0f2288c51ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_FRAME = 10\n",
    "FRAMES_TO_PROC = 5\n",
    "imgs_dir = 'football'\n",
    "get_frames(\n",
    "    vid_path,\n",
    "    START_FRAME,\n",
    "    FRAMES_TO_PROC,\n",
    "    WORK_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa317b-1832-435f-8fae-55ccd3d4c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la $WORK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b795ddf-90c7-4aac-8281-81ab0bfda615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(WORK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ed374-55e0-45ef-b29b-ef36278aa8d5",
   "metadata": {},
   "source": [
    "### 3. YOLO one image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f39685-52f6-4c5b-b4bd-87042cc35da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load an official model\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30929053-b260-4870-8bc8-9202f11f7dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_img_path = f'{WORK_DIR}/{os.listdir(WORK_DIR)[0]}'\n",
    "print('test image:', test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54661b7-4230-4c14-a800-29c17b5be58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run batched inference on a list of images\n",
    "results = model(test_img_path)  # return a list of Results objects\n",
    "print('total results:', len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad3ff1-7c8b-4965-a953-2dc522a6b34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f90022-70f9-4792-ba77-f3a880ed3c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show results\n",
    "for result in results:\n",
    "    boxes = result.boxes  # boxes object for bounding box outputs\n",
    "    im_bgr = result.plot()  # BGR-order numpy array\n",
    "    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.imshow(im_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5229734-61a9-4837-8fa1-df07956a130e",
   "metadata": {},
   "source": [
    "Next steps could be:\n",
    "1. Find unique features ti identify every player detected\n",
    "2. Build an algorithm of tracking players through the series of frames\n",
    "3. Process frame by frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6204a2d6-6950-47f2-9d8c-97e10039d2ea",
   "metadata": {},
   "source": [
    "### 4. YOLO tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c815fa54-38e1-45d3-b98c-6c3be0ad07be",
   "metadata": {},
   "source": [
    "YOLO offers a ready solution for tracking objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823243a0-6662-4b14-a005-af32b63c47d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_FRAME = 250\n",
    "FRAMES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f4cde-95dd-4ee3-829b-f236526db27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracked_frames = []\n",
    "counter = 0\n",
    "# move cursor to start frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, START_FRAME)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        # run YOLO tracking on the frame,\n",
    "        # persisting tracks between frames\n",
    "        results = model.track(frame, persist=True)\n",
    "        annotated_frame = results[0].plot()\n",
    "        annotated_frame = annotated_frame[..., ::-1]  # convert to RGB\n",
    "        tracked_frames.append(annotated_frame)\n",
    "        counter += 1\n",
    "        if counter >= FRAMES:\n",
    "            break\n",
    "    else:\n",
    "        # break the loop if the end of the video is reached\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9e2d5-bc1e-45e5-8b5e-1b93846ca2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine video from frames with tracked objects\n",
    "# and write this video to disk\n",
    "out = cv2.VideoWriter(\n",
    "    'video_with_tracking.avi',\n",
    "    cv2.VideoWriter_fourcc(*'DIVX'),\n",
    "    cap.get(5),  # fps rate\n",
    "    (int(cap.get(3)), int(cap.get(4))),  # resolution params\n",
    ")\n",
    "for frame in tqdm(tracked_frames):\n",
    "    out.write(frame)\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d902c995-6685-4dc4-8029-98a0fc541491",
   "metadata": {},
   "source": [
    "What problems still need to be solved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc737d5-c2c4-4d66-b06b-95dc71113317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
