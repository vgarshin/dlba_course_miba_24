{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffce6178-db6f-4e02-81af-110743e4a54a",
   "metadata": {},
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de86042-6532-46d8-9004-c0c5be6fa00d",
   "metadata": {},
   "source": [
    "## TOPIC 2: Introduction to Computer Vision. Intro to CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b9c30-1d1a-4306-8ea4-109ec854bb4a",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922224a-319e-4069-806d-fbf672643647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04dc8e-54f6-4a2e-bca4-d534d97498e9",
   "metadata": {},
   "source": [
    "### 2. MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041c46d-9b94-43ef-a14d-380e9de93f0d",
   "metadata": {},
   "source": [
    "About [MNIST dataset](https://yann.lecun.com/exdb/mnist/):\n",
    "- handwritten digits 0, 1, â€¦, 9\n",
    "- 28x28 size (784 pixels)\n",
    "- training set of 60 000 and a test set of 10 000 examples\n",
    "- grey scale colored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984f65a-43ba-42de-a46f-767186c82371",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1a5fc-7020-46ec-9971-2eefececa26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST('./data', download=True)\n",
    "test_data = torchvision.datasets.MNIST('data', train=False)\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7330a2a-a857-457e-af51-6dcfcf44292a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "image, label = train_data[0]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('label of image: {}'.format(label), fontsize=14)\n",
    "plt.subplot(1, 2, 2)\n",
    "image, label = train_data[1]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('label of image: {}'.format(label), fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f38e8-e912-4482-b856-5f4e51e7c383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a91039-5b5e-4f07-85e0-e35f4523f60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_arr = np.asarray(image)\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88233a7-3a16-4f74-846b-00167a787ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1db5b-525a-42ac-8277-be55a31d2411",
   "metadata": {},
   "source": [
    "### 2.2. Basic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a96e7-11a7-4db1-9e28-6b68a4054d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: NN likes input in range (0, 1)\n",
    "# Convert input images to tensors and normalize\n",
    "# Usually, 'transforms.ToTensor()' is used to turn\n",
    "# the input data in the range # of [0,255]\n",
    "# to a 3-dimensional Tensor.\n",
    "# This function automatically scales the\n",
    "# input data to the range of [0,1].\n",
    "# (This is equivalent to scaling the data down to 0,1)\n",
    "# The scaled mean and standard deviation\n",
    "# of the MNIST dataset (precalculated):\n",
    "# data_mean = 0.1307\n",
    "# data_std = 0.3081\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.Normalize(  # apply if needed\n",
    "    #    (data_mean, ),\n",
    "    #    (data_std, )\n",
    "    #)\n",
    "    ])\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    'data',\n",
    "    train=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    'data',\n",
    "    train=False,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ede4e-5976-4377-a741-7f5de7101945",
   "metadata": {},
   "source": [
    "## 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a9568-5f11-4bb0-a019-13660eaeaec1",
   "metadata": {},
   "source": [
    "### 3.1. Data loaders for training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5197cd-50a1-46a3-8ad6-d5401c706082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "INPUT_SIZE = 28 * 28\n",
    "NUM_CLASSES = 10\n",
    "LEARNING_RATE = .001\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ecf7b-948b-4af0-b57d-d2cf0bd49583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f0760b-c14f-481e-ba09-33a5246e9aba",
   "metadata": {},
   "source": [
    "### 3.2. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751fe5e-ff83-4b01-9661-9263427c7dd0",
   "metadata": {},
   "source": [
    "Let's implement logistic regression with help of Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e4c80-6a99-4931-9803-fa2103c1abdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just one fully connected layer\n",
    "# will give us a regression\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        output = self.linear(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04040106-2593-47cb-9401-1eddfcfa1db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(\n",
    "    INPUT_SIZE,\n",
    "    NUM_CLASSES\n",
    ")\n",
    "\n",
    "# The Cross-Entropy Loss is derived from the principles of maximum\n",
    "# likelihood estimation when applied to the task of classification.\n",
    "# Maximizing the likelihood is equivalent to minimizing the negative\n",
    "# log-likelihood. In classification, the likelihood function can be\n",
    "# expressed as the product of the probabilities of the correct classes:\n",
    "# Binary Cross-Entropy Loss and Multiclass Cross-Entropy Loss\n",
    "# are two variants of cross-entropy loss, each tailored to different\n",
    "# types of classification tasks:\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# about `Adam` optimizer\n",
    "# https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    "# it works well in most of cases\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48659166-ba11-4c41-8667-3662088dcacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = torch.autograd.Variable(images.view(-1, INPUT_SIZE))\n",
    "        labels = torch.autograd.Variable(labels)\n",
    "\n",
    "        # nullify gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output = model(images)\n",
    "        # compute loss based on obtained value and actual label\n",
    "        compute_loss = loss(output, labels)\n",
    "        # backward propagation\n",
    "        compute_loss.backward()\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Total correct predictions\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        correct += (predicted == labels).sum()\n",
    "        if i % 50 == 0:\n",
    "            print(\n",
    "                'Epoch {} - training [{}/{} ({:.0f}%)] loss: {:.3f}, accuracy: {:.2f}%'.format(\n",
    "                    epoch,\n",
    "                    i * len(images),\n",
    "                    len(train_loader.dataset),\n",
    "                    100 * i / len(train_loader),\n",
    "                    compute_loss.item(),\n",
    "                    float(correct * 100) / float(BATCH_SIZE * (i + 1))\n",
    "                ),\n",
    "                end='\\r'\n",
    "            )\n",
    "\n",
    "    # check total accuracy of predicted value and actual label\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = torch.autograd.Variable(images.view(-1, INPUT_SIZE))\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        compute_loss = loss(output, labels)\n",
    "        # total labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        accurate += (predicted == labels).sum()\n",
    "        accuracy_score = 100 * accurate/total\n",
    "\n",
    "    print('Epoch {} - validation loss: {:.3f}, validation accuracy: {:.2f}%        '.format(\n",
    "        epoch,\n",
    "        compute_loss.item(),\n",
    "        accuracy_score\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b66838-8a22-4f1f-ab55-bbf13680df51",
   "metadata": {},
   "source": [
    "### 3.3. CNN approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c60cd4-1a8a-4e9f-816d-0301d4d336b2",
   "metadata": {},
   "source": [
    "Now will use simple convolutional neural network with couple of convolutional layers. Few points before network building:\n",
    "- [about](https://docs.python.org/3/library/functions.html#super) `super` in Python. It allows you to call methods defined in the superclass from the subclass, enabling you to extend and customize the functionality inherited from the parent class\n",
    "- [about](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) `Conv2d` layer in Pytorch\n",
    "- [about](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) `Dropout` layers in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496cfaa-b9a0-4dbf-82ef-c6815498ed39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding='valid')\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding='valid')\n",
    "        self.dropout1 = nn.Dropout(.5)\n",
    "        self.dropout2 = nn.Dropout(.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)  # you may need to comment this line for HA\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)  # you may need to comment this line for HA\n",
    "        x = self.fc2(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324642f-92eb-4a53-9db9-c96b4bcf893e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleCNN(NUM_CLASSES)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b8c52-1843-455a-9524-26ed9f09c964",
   "metadata": {},
   "source": [
    "### <font color='red'>HOME ASSIGNMENT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5ad67-9127-48ed-9dab-95a06c8c05c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "You have to make few experiments:\n",
    "1. Just run training CNN framework (code cell below) and observe if validation accuracy changes (get higher or lower)\n",
    "2. Try to play with `Dropout` layers e.g. remove them, re-run model creation and training cells of the notebook, observe if validation accuracy changes (get higher or lower)\n",
    "3. __(ADVANCED)__ Try CNN without `max_pool2d` layer, what has happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a2c29-5fd2-4aaa-992b-27e87d6dfe9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = torch.autograd.Variable(images)\n",
    "        labels = torch.autograd.Variable(labels)\n",
    "\n",
    "        # Nullify gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output = model(images)\n",
    "        # compute loss based on obtained value and actual label\n",
    "        compute_loss = loss(output, labels)\n",
    "        # backward propagation\n",
    "        compute_loss.backward()\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # total correct predictions\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        correct += (predicted == labels).sum()\n",
    "        if i % 50 == 0:\n",
    "            print(\n",
    "                'Epoch {} - training [{}/{} ({:.0f}%)] loss: {:.3f}, accuracy: {:.2f}%'.format(\n",
    "                    epoch,\n",
    "                    i * len(images),\n",
    "                    len(train_loader.dataset),\n",
    "                    100 * i / len(train_loader),\n",
    "                    compute_loss.item(),\n",
    "                    float(correct * 100) / float(BATCH_SIZE * (i + 1))\n",
    "                ),\n",
    "                end='\\r'\n",
    "            )\n",
    "\n",
    "    # check total accuracy of predicted value and actual label\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = torch.autograd.Variable(images)\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        compute_loss = loss(output, labels)\n",
    "        # total labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # total correct predictions\n",
    "        accurate += (predicted == labels).sum()\n",
    "        accuracy_score = 100 * accurate/total\n",
    "\n",
    "    print('Epoch {} - validation loss: {:.3f}, validation accuracy: {:.2f}%        '.format(\n",
    "        epoch,\n",
    "        compute_loss.item(),\n",
    "        accuracy_score\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba94cd02-2090-44d0-885b-74561b11bbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
