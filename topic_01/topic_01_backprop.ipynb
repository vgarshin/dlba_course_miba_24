{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dcad67-0c83-4c39-9cef-49cbf2cc0057",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94caaa-b5e0-4fe9-aa69-74e786442a1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TOPIC 1: Introduction to Deep Learning. Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f1f19-82d0-48ed-b338-ca53c580284b",
   "metadata": {},
   "source": [
    "Based on [this article](https://www.geeksforgeeks.org/backpropagation-in-neural-network/) and [this repository](https://github.com/jgabriellima/backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16bb11f-3b5b-4449-90e2-9bb0dbf7ba40",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe87dea-ca34-4067-8824-d7391e7d877c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddaef49-6086-47b1-b5ab-8341024ea527",
   "metadata": {},
   "source": [
    "### 2. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af0adc-7352-426f-8f11-4438c6d51782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand(a, b):\n",
    "    \"\"\"\n",
    "    Returns a random number between `a` and `b`\n",
    "\n",
    "    \"\"\"\n",
    "    return (b - a) * random.random() + a\n",
    "\n",
    "\n",
    "def matrix(i_size, j_size, fill=0):\n",
    "    \"\"\"\n",
    "    Returns a matrix with size (i_size, j_size)\n",
    "\n",
    "    \"\"\"\n",
    "    m = []\n",
    "    for i in range(i_size):\n",
    "        m.append([fill] * j_size)\n",
    "    return m\n",
    "\n",
    "\n",
    "def afunc(x):\n",
    "    \"\"\"\n",
    "    Activation function, with `tanh`\n",
    "    instead of the sigmoid `1 / (1 + e ** -x)`\n",
    "\n",
    "    \"\"\"\n",
    "    return math.tanh(x)\n",
    "\n",
    "\n",
    "def dafunc(x):\n",
    "    \"\"\"\n",
    "    Derivative of our activation function\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 - x ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55073225-a579-44a2-9122-34dd6beb9078",
   "metadata": {},
   "source": [
    "### 3. Define our Neural Network (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de3898-96b5-4988-b02a-74feb25a8dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        # number of input, hidden, and output nodes\n",
    "        self.ni = ni + 1  # `+1` is for bias node\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "\n",
    "        # activations for nodes\n",
    "        self.ai = [1] * self.ni\n",
    "        self.ah = [1] * self.nh\n",
    "        self.ao = [1] * self.no\n",
    "\n",
    "        # create weights\n",
    "        self.wi = matrix(self.ni, self.nh)\n",
    "        self.wo = matrix(self.nh, self.no)\n",
    "        # initialize them with random vaules\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                self.wi[i][j] = rand(-0.2, 0.2)\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                self.wo[j][k] = rand(-2.0, 2.0)\n",
    "\n",
    "        # last change in weights for momentum\n",
    "        self.ci = matrix(self.ni, self.nh)\n",
    "        self.co = matrix(self.nh, self.no)\n",
    "\n",
    "    def update(self, inputs):\n",
    "        \"\"\"\n",
    "        Returns outputs of the neural netork\n",
    "\n",
    "        \"\"\"\n",
    "        if len(inputs) != self.ni-1:\n",
    "            raise ValueError('wrong number of inputs')\n",
    "\n",
    "        # input activations\n",
    "        for i in range(self.ni - 1):\n",
    "            self.ai[i] = inputs[i]\n",
    "\n",
    "        # hidden activations\n",
    "        for j in range(self.nh):\n",
    "            hsum = 0\n",
    "            for i in range(self.ni):\n",
    "                hsum = hsum + self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = afunc(hsum)\n",
    "\n",
    "        # output activations\n",
    "        for k in range(self.no):\n",
    "            osum = 0\n",
    "            for j in range(self.nh):\n",
    "                osum = osum + self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = afunc(osum)\n",
    "\n",
    "        return self.ao[:]\n",
    "\n",
    "    def back_propagate(self, targets, lr, mm):\n",
    "        \"\"\"\n",
    "        Core of the backpropagation algorithm is here\n",
    "\n",
    "        \"\"\"\n",
    "        if len(targets) != self.no:\n",
    "            raise ValueError('wrong number of target values')\n",
    "\n",
    "        # calculate error terms for output\n",
    "        output_deltas = [0] * self.no\n",
    "        for k in range(self.no):\n",
    "            error = targets[k] - self.ao[k]\n",
    "            output_deltas[k] = dafunc(self.ao[k]) * error\n",
    "\n",
    "        # calculate error terms for hidden\n",
    "        hidden_deltas = [0] * self.nh\n",
    "        for j in range(self.nh):\n",
    "            error = 0\n",
    "            for k in range(self.no):\n",
    "                error = error + output_deltas[k] * self.wo[j][k]\n",
    "            hidden_deltas[j] = dafunc(self.ah[j]) * error\n",
    "\n",
    "        # update output weights\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                change = output_deltas[k] * self.ah[j]\n",
    "                self.wo[j][k] = self.wo[j][k] + lr * change + mm * self.co[j][k]\n",
    "                self.co[j][k] = change\n",
    "\n",
    "        # update input weights\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                change = hidden_deltas[j]*self.ai[i]\n",
    "                self.wi[i][j] = self.wi[i][j] + lr * change + mm * self.ci[i][j]\n",
    "                self.ci[i][j] = change\n",
    "\n",
    "        # calculate error\n",
    "        error = 0\n",
    "        for k in range(len(targets)):\n",
    "            error = error + .5 * (targets[k] - self.ao[k]) ** 2\n",
    "        return error\n",
    "\n",
    "    def test(self, patterns):\n",
    "        \"\"\"\n",
    "        Prints outputs of the neural network\n",
    "        for a test input pattern\n",
    "\n",
    "        \"\"\"\n",
    "        for p in patterns:\n",
    "            print(p[0], '->', self.update(p[0]))\n",
    "\n",
    "    def weights(self):\n",
    "        \"\"\"\n",
    "        Prints weights of the neural network\n",
    "\n",
    "        \"\"\"\n",
    "        print('Input weights:')\n",
    "        for i in range(self.ni):\n",
    "            print(self.wi[i])\n",
    "        print()\n",
    "        print('Output weights:')\n",
    "        for j in range(self.nh):\n",
    "            print(self.wo[j])\n",
    "\n",
    "    def train(self, patterns, iterations=1000, lr=.5, mm=0.1):\n",
    "        \"\"\"\n",
    "        Train neural network with help\n",
    "        of backpropagation algorithm\n",
    "\n",
    "        :lr: learning rate\n",
    "        :mm: momentum factor\n",
    "\n",
    "        \"\"\"\n",
    "        for i in range(iterations):\n",
    "            error = 0\n",
    "            for p in patterns:\n",
    "                inputs = p[0]\n",
    "                targets = p[1]\n",
    "                self.update(inputs)\n",
    "                error = error + self.back_propagate(targets, lr, mm)\n",
    "            if i % 100 == 0:\n",
    "                print('error at iteration {} is {:.4f}'.format(i, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c189c24-0046-4d13-9bf0-2cadd7c4c483",
   "metadata": {},
   "source": [
    "### 4. Training neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ecf1-a5e9-43fd-aa51-9bc439729027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a network with two input,\n",
    "# two hidden, and one output nodes\n",
    "\n",
    "nn = NN(2, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd60004-83a4-4d47-8815-5c61f6814145",
   "metadata": {},
   "source": [
    "Few ords about [AND, NOT, OR and XOR operations](https://www.geeksforgeeks.org/complete-reference-for-bitwise-operators-in-programming-coding/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105482a1-eee3-41e8-9414-8d2908484577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's take XOR operations\n",
    "# as a training data\n",
    "pattern_xor = [\n",
    "    [[0,0], [0]],\n",
    "    [[0,1], [1]],\n",
    "    [[1,0], [1]],\n",
    "    [[1,1], [0]]\n",
    "]\n",
    "\n",
    "# ...and train it with some patterns\n",
    "nn.train(pattern_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9ddd0-5b86-4be9-939f-d7ca5416fb98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test our trained neyork\n",
    "nn.test(pattern_xor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a994d-70a2-44ce-bb49-7f0f92294925",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color='red'>HOME ASSIGNMENT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45cf1b-4b1c-4fa1-bfea-4d828f899876",
   "metadata": {},
   "source": [
    "Please, train neural network for AND and OR operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231731b6-b2d6-4cc0-8de7-4b6fcdfcb752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HINT:\n",
    "# you need a new `pattern` for AND or OR\n",
    "# operations only. No need to change the code\n",
    "# for network, just train new NN with new pattern\n",
    "\n",
    "pattern_new = [\n",
    "    # Your code will be here\n",
    "]\n",
    "nn = NN(2, 2, 1)\n",
    "nn.train(pattern_and)\n",
    "nn.test(pattern_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036c89e-56b7-469e-a3ac-515428e305ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
