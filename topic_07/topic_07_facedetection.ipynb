{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29d4caf-dba9-4b5c-a287-2d3298468a7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c7d69-e6c7-4777-8ad3-a077cac990be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TOPIC 7: Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ae5f5-ae3a-4a0d-af72-a5c39fda3cee",
   "metadata": {},
   "source": [
    "### 1. Library installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c29004-7da5-4df5-a304-692a09cc7c33",
   "metadata": {},
   "source": [
    "Documentation for use of OpenCV with Python API [see here](https://docs.opencv.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d103aab-ffd3-4870-880d-e1b55f269086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0425367-4dec-4ed3-8b05-cf10e4fac8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752ae22-d6c6-4898-98c5-b24bf34f900f",
   "metadata": {},
   "source": [
    "### 2. Haarcascades approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c65f4-b55d-4ce8-b7db-715b2dd99398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the required trained XML classifiers\n",
    "# https://github.com/Itseez/opencv/blob/master/\n",
    "# data/haarcascades/haarcascade_frontalface_default.xml\n",
    "# Trained XML classifiers describes some features of some\n",
    "# object we want to detect a cascade function is trained\n",
    "# from a lot of positive(faces) and negative(non-faces)\n",
    "# images.\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# https://github.com/Itseez/opencv/blob/master\n",
    "# /data/haarcascades/haarcascade_eye.xml\n",
    "# Trained XML file for detecting eyes\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb30e61-f05e-4957-b351-04184e833ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "face_cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7b1f0-04ba-4d6b-a418-9eb3dbd4e477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = 'imgs/faces1.jpg'\n",
    "img = cv2.imread(file_path)\n",
    "assert img is not None, 'file could not be read, check if file exists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c74bb-d580-40bf-8fdb-7de56a4521a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RGBimage = cv2.cvtColor(BGRimage, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae946d2-b2cf-43b4-abea-4d5eddce864d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4d076-2cf8-4a9e-94c4-ff3f0d2809a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Detects faces of different sizes in the input image\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61edd835-d3c2-4e09-8b02-11f754e4e45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, (x,y,w,h) in enumerate(faces):\n",
    "    # To draw a rectangle in a face \n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2) \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        f'face {i}',\n",
    "        (x, y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        2,\n",
    "        (255, 255, 0),\n",
    "        3\n",
    "    )\n",
    "\n",
    "    # Detects eyes of different sizes in the input image\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray) \n",
    "\n",
    "    # To draw a rectangle in eyes\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,127,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd95fe7-6c4b-4dfb-a00f-414bbb701b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display an image in a window\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a8c34a-c622-4370-8de3-00d198098a93",
   "metadata": {},
   "source": [
    "### 3. CNN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1077b-0c97-414a-bd74-4e8b8f3332cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8f31a-625b-4192-9b22-0cc9a84337c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a921c6-7ade-4e5f-90ea-09a30908dd00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = f'imgs/faces1.jpg'\n",
    "img = Image.open(img_path)\n",
    "img_ = np.array(img)\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ced5b-23aa-4f95-a3ca-1dd510a355af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model and image processor\n",
    "model_name = 'diffusionai/detr-face-detection'\n",
    "processor = DetrImageProcessor.from_pretrained(model_name)\n",
    "model = DetrForObjectDetection.from_pretrained(model_name)\n",
    "\n",
    "# inference for detection\n",
    "inputs = processor(images=img, return_tensors='pt')\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5562343b-058e-4be1-97da-07696f3e7b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# let's only keep detections with score > 0.9\n",
    "th = .9\n",
    "target_sizes = torch.tensor([img.size[::-1]])\n",
    "results = processor.post_process_object_detection(\n",
    "    outputs,\n",
    "    target_sizes=target_sizes,\n",
    "    threshold=th\n",
    ")[0]\n",
    "\n",
    "# results and bbox drawing\n",
    "for i, (score, box) in enumerate(zip(results['scores'], results['boxes'])):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "            f'detected face {i} with confidence',\n",
    "            f'{round(score.item(), 2)} at location {box}'\n",
    "    )\n",
    "\n",
    "    top_left = (int(box[0]), int(box[1]))\n",
    "    bottom_right = (int(box[2]), int(box[3]))\n",
    "    cv2.rectangle(img_, top_left, bottom_right, (0, 255, 0), 3)\n",
    "    cv2.putText(\n",
    "        img_,\n",
    "        f'face {i}',\n",
    "        top_left,\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        2,\n",
    "        (0, 255, 0),\n",
    "        3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359d161-2599-47d0-b3bc-bf929190fbd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.imshow(img_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e2589-5f00-4c6a-948c-e2fa7a8f40fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
